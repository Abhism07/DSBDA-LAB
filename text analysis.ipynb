{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f0067d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db970abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex=\"Developing writers can often benefit from examining an essay, a paragraph, or even a sentence to determine what makes it effective. On the following pages are several paragraphs for you to evaluate on your own, along with the Writing Center's explanation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d58545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex=ex.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5944bc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f506d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['developing writers can often benefit from examining an essay, a paragraph, or even a sentence to determine what makes it effective.',\n",
       " \"on the following pages are several paragraphs for you to evaluate on your own, along with the writing center's explanation.\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sent = sent_tokenize(ex)\n",
    "tokenized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6eacbf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['developing',\n",
       " 'writers',\n",
       " 'can',\n",
       " 'often',\n",
       " 'benefit',\n",
       " 'from',\n",
       " 'examining',\n",
       " 'an',\n",
       " 'essay',\n",
       " ',',\n",
       " 'a',\n",
       " 'paragraph',\n",
       " ',',\n",
       " 'or',\n",
       " 'even',\n",
       " 'a',\n",
       " 'sentence',\n",
       " 'to',\n",
       " 'determine',\n",
       " 'what',\n",
       " 'makes',\n",
       " 'it',\n",
       " 'effective',\n",
       " '.',\n",
       " 'on',\n",
       " 'the',\n",
       " 'following',\n",
       " 'pages',\n",
       " 'are',\n",
       " 'several',\n",
       " 'paragraphs',\n",
       " 'for',\n",
       " 'you',\n",
       " 'to',\n",
       " 'evaluate',\n",
       " 'on',\n",
       " 'your',\n",
       " 'own',\n",
       " ',',\n",
       " 'along',\n",
       " 'with',\n",
       " 'the',\n",
       " 'writing',\n",
       " 'center',\n",
       " \"'s\",\n",
       " 'explanation',\n",
       " '.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_word = word_tokenize(ex)\n",
    "tokenized_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d47e7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4f4eed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "punc = string.punctuation\n",
    "punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d7320e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1244a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['developing',\n",
       " 'writers',\n",
       " 'often',\n",
       " 'benefit',\n",
       " 'examining',\n",
       " 'essay',\n",
       " ',',\n",
       " 'paragraph',\n",
       " ',',\n",
       " 'even',\n",
       " 'sentence',\n",
       " 'determine',\n",
       " 'makes',\n",
       " 'effective',\n",
       " '.',\n",
       " 'following',\n",
       " 'pages',\n",
       " 'several',\n",
       " 'paragraphs',\n",
       " 'evaluate',\n",
       " ',',\n",
       " 'along',\n",
       " 'writing',\n",
       " 'center',\n",
       " \"'s\",\n",
       " 'explanation',\n",
       " '.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [c for c in tokenized_word if c not in stopwords.words('english')]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4284b8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['developing',\n",
       " 'writers',\n",
       " 'often',\n",
       " 'benefit',\n",
       " 'examining',\n",
       " 'essay',\n",
       " 'paragraph',\n",
       " 'even',\n",
       " 'sentence',\n",
       " 'determine',\n",
       " 'makes',\n",
       " 'effective',\n",
       " 'following',\n",
       " 'pages',\n",
       " 'several',\n",
       " 'paragraphs',\n",
       " 'evaluate',\n",
       " 'along',\n",
       " 'writing',\n",
       " 'center',\n",
       " \"'s\",\n",
       " 'explanation']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [c for c in words if c not in punc]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ddb3d82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f07ab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('developing', 'VBG'),\n",
       " ('writers', 'NNS'),\n",
       " ('often', 'RB'),\n",
       " ('benefit', 'VBP'),\n",
       " ('examining', 'VBG'),\n",
       " ('essay', 'VBP'),\n",
       " ('paragraph', 'NNS'),\n",
       " ('even', 'RB'),\n",
       " ('sentence', 'VBP'),\n",
       " ('determine', 'JJ'),\n",
       " ('makes', 'VBZ'),\n",
       " ('effective', 'JJ'),\n",
       " ('following', 'VBG'),\n",
       " ('pages', 'NNS'),\n",
       " ('several', 'JJ'),\n",
       " ('paragraphs', 'JJ'),\n",
       " ('evaluate', 'NN'),\n",
       " ('along', 'IN'),\n",
       " ('writing', 'VBG'),\n",
       " ('center', 'NN'),\n",
       " (\"'s\", 'POS'),\n",
       " ('explanation', 'NN')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad6e44fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "develop\n",
      "writer\n",
      "often\n",
      "benefit\n",
      "examin\n",
      "essay\n",
      "paragraph\n",
      "even\n",
      "sentenc\n",
      "determin\n",
      "make\n",
      "effect\n",
      "follow\n",
      "page\n",
      "sever\n",
      "paragraph\n",
      "evalu\n",
      "along\n",
      "write\n",
      "center\n",
      "'s\n",
      "explan\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "934045aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2109fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1224d539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "developing\n",
      "writer\n",
      "often\n",
      "benefit\n",
      "examining\n",
      "essay\n",
      "paragraph\n",
      "even\n",
      "sentence\n",
      "determine\n",
      "make\n",
      "effective\n",
      "following\n",
      "page\n",
      "several\n",
      "paragraph\n",
      "evaluate\n",
      "along\n",
      "writing\n",
      "center\n",
      "'s\n",
      "explanation\n"
     ]
    }
   ],
   "source": [
    "lm = WordNetLemmatizer()\n",
    "for w in words:\n",
    "    ltq=lm.lemmatize(w)\n",
    "    print(ltq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1cddb1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "249e04ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4)\t1.0\n",
      "  (1, 19)\t1.0\n",
      "  (2, 13)\t1.0\n",
      "  (3, 1)\t1.0\n",
      "  (4, 9)\t1.0\n",
      "  (5, 6)\t1.0\n",
      "  (6, 15)\t1.0\n",
      "  (7, 8)\t1.0\n",
      "  (8, 17)\t1.0\n",
      "  (9, 3)\t1.0\n",
      "  (10, 12)\t1.0\n",
      "  (11, 5)\t1.0\n",
      "  (12, 11)\t1.0\n",
      "  (13, 14)\t1.0\n",
      "  (14, 18)\t1.0\n",
      "  (15, 16)\t1.0\n",
      "  (16, 7)\t1.0\n",
      "  (17, 0)\t1.0\n",
      "  (18, 20)\t1.0\n",
      "  (19, 2)\t1.0\n",
      "  (21, 10)\t1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22, 21)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "x = vectorizer.fit_transform(words)\n",
    "print(x)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a2115ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['developing'], dtype='<U11'),\n",
       " array(['writers'], dtype='<U11'),\n",
       " array(['often'], dtype='<U11'),\n",
       " array(['benefit'], dtype='<U11'),\n",
       " array(['examining'], dtype='<U11'),\n",
       " array(['essay'], dtype='<U11'),\n",
       " array(['paragraph'], dtype='<U11'),\n",
       " array(['even'], dtype='<U11'),\n",
       " array(['sentence'], dtype='<U11'),\n",
       " array(['determine'], dtype='<U11'),\n",
       " array(['makes'], dtype='<U11'),\n",
       " array(['effective'], dtype='<U11'),\n",
       " array(['following'], dtype='<U11'),\n",
       " array(['pages'], dtype='<U11'),\n",
       " array(['several'], dtype='<U11'),\n",
       " array(['paragraphs'], dtype='<U11'),\n",
       " array(['evaluate'], dtype='<U11'),\n",
       " array(['along'], dtype='<U11'),\n",
       " array(['writing'], dtype='<U11'),\n",
       " array(['center'], dtype='<U11'),\n",
       " array([], dtype='<U11'),\n",
       " array(['explanation'], dtype='<U11')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.inverse_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7498ee02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6693b18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
